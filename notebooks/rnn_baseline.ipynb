{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Baseline Implementation\n",
    "\n",
    "\n",
    "Basic outline of the Notebook:\n",
    "1. Environment setup\n",
    "2. Model definition\n",
    "3. Train and Validate functions\n",
    "4. Set hyperparameters\n",
    "5. Data Loading\n",
    "6. Training\n",
    "7. Testing\n",
    "8. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9e9ba84db6d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.dataset import *\n",
    "from src.utils import *\n",
    "\n",
    "from einops import rearrange  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model definition\n",
    "\n",
    "The model architecture is as defined below:\n",
    "\n",
    "![RNN Model Architecture](./images/rnn_baseline.jpeg \"RNN Baseline Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRNN(nn.Module):\n",
    "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
    "        super(ImageRNN, self).__init__()\n",
    "\n",
    "        self.n_neurons = n_neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.n_steps = n_steps\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.layer1 = nn.RNN(self.n_inputs, self.n_neurons)\n",
    "        self.layer2 = nn.Linear(self.n_neurons, self.n_outputs)\n",
    "\n",
    "    def init_hidden(self,):\n",
    "        return torch.zeros(1, self.batch_size, self.n_neurons)\n",
    "\n",
    "    def forward(self, X, h_init):\n",
    "        \n",
    "        # Transforms X to dimensions: n_steps X batch_size X n_inputs\n",
    "        X = X.permute(1, 0, 2)\n",
    "\n",
    "        h_seq , h_final = self.layer1(X , h_init)\n",
    "        score_seq = self.layer2(h_final)\n",
    "\n",
    "        return score_seq.view(-1, self.n_outputs), h_final #out.view(-1, self.n_outputs)  # batch_size X n_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Validate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, train_data, device):\n",
    "    \n",
    "    model.train()\n",
    "    counter = 0\n",
    "    \n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    running_error = 0.0\n",
    "    \n",
    "    h = torch.zeros(1, model.batch_size, model.n_neurons)\n",
    "    h = h.to(device)\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        counter += 1\n",
    "\n",
    "        # Get image patches from the input to feed to the RNN.\n",
    "        inputs, labels = data.values()\n",
    "        img_patches = rearrange(\n",
    "            inputs.view(model.batch_size, 3, 144, 256),\n",
    "            \"b c (patch_x x) (patch_y y) -> b (x y) (patch_x patch_y c)\",\n",
    "            patch_x=PATCH_SIZE,\n",
    "            patch_y=PATCH_SIZE,\n",
    "        )\n",
    "\n",
    "        img_patches = img_patches.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        h = h.detach()\n",
    "        h = h.requires_grad_()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, h = model(img_patches, h)\n",
    "        outputs = torch.sigmoid(outputs).to(device)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "        running_error += get_error(outputs.detach(), labels, model.batch_size)\n",
    "        running_acc += get_accuracy(outputs.detach(), labels, model.batch_size)\n",
    "        \n",
    "    total_loss = train_running_loss / counter\n",
    "    total_error = train_running_error / counter\n",
    "\n",
    "    return total_loss, total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, val_data, device):\n",
    "   \n",
    "    model.eval()\n",
    "    \n",
    "    counter = 0\n",
    "    running_loss = 0.0\n",
    "    running_error = 0.0\n",
    "    \n",
    "    h = torch.zeros(1, model.batch_size, model.n_neurons)\n",
    "    h = h.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            # Get image patches from the input to feed to the RNN.\n",
    "            inputs, labels = data.values()\n",
    "            img_patches = rearrange(\n",
    "                inputs.view(model.batch_size, 3, 144, 256),\n",
    "                \"b c (patch_x x) (patch_y y) -> b (x y) (patch_x patch_y c)\",\n",
    "                patch_x=PATCH_SIZE,\n",
    "                patch_y=PATCH_SIZE,\n",
    "            )\n",
    "            img_patches = img_patches.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(img_patches)\n",
    "            \n",
    "            # Apply sigmoid activation to get all the outputs between 0 and 1\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_error += get_error(outputs, target, batch_size)\n",
    "    total_loss = running_loss / counter\n",
    "    total_error = running_error / counter\n",
    "    return total_loss, total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 144\n",
    "N_INPUTS = 768\n",
    "N_NEURONS = 150\n",
    "N_OUTPUTS = 6\n",
    "\n",
    "N_EPHOCS = 20\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "LR = 0.1\n",
    "PATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4f2588d6c1e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_STEPS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_INPUTS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_NEURONS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_OUTPUTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay_num_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImageRNN(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
    "model = model.to(device)\n",
    "display_num_param(model)\n",
    "print(model)\n",
    "lr = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9705150f2e0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataset(train=True)\n",
    "valid_data = ImageDataset(train=False)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7ab035abd33e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_epoch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_epoch_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N_EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_epoch_loss, total_epoch_error = train(model, train_loader, optimizer, criterion, train_data, device)\n",
    "    valid_epoch_loss, valid_epoch_error = validate(model, valid_loader, criterion, valid_data, device)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "\n",
    "    print(\n",
    "        \"Epoch:  %d | Train Loss: %.4f | Train Error: %.2f Val Loss: %.4f | Val Error: %.2f\\n\"\n",
    "        % (epoch, train_epoch_loss, train_epoch_error, valid_epoch_loss, valid_epoch_error)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2302326b62db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mactors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'actors: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_csv' is not defined"
     ]
    }
   ],
   "source": [
    "actors = train_csv.columns.values[2:]\n",
    "print('actors: ', actors)\n",
    "\n",
    "test_data = ImageDataset(train=False)\n",
    "print(test_data[0]['image'].shape, test_data[0]['label'].shape)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-805c54f0e7d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtarget_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "running_error = 0.0\n",
    "running_acc = 0.0\n",
    "output_list = []\n",
    "target_list = []\n",
    "\n",
    "for counter, data in enumerate(test_loader):\n",
    "\n",
    "    h = torch.zeros(1, BATCH_SIZE, model.n_neurons)\n",
    "    h = h.to(device)\n",
    "    inputs, labels = data.values()\n",
    "    target_indices = [i for i in range(len(labels[0])) if labels[0][i] == 1]\n",
    "    img_patches = rearrange(\n",
    "        inputs.view(BATCH_SIZE, 3, 144, 256),\n",
    "        \"b c (patch_x x) (patch_y y) -> b (x y) (patch_x patch_y c)\",\n",
    "        patch_x=PATCH_SIZE,\n",
    "        patch_y=PATCH_SIZE,\n",
    "    )\n",
    "    img_patches = img_patches.to(device)\n",
    "    labels = labels.to(device)\n",
    "    h = h.detach()\n",
    "    h = h.requires_grad_()\n",
    "\n",
    "    outputs, h = model(img_patches, h)\n",
    "    outputs = torch.sigmoid(outputs)\n",
    "    outputs = outputs.detach().cpu()\n",
    "    \n",
    "    lab = torch.where(outputs>=0.5,1,0)[0]\n",
    "    pred = torch.where(lab==1)\n",
    "    \n",
    "    running_error += get_error(outputs, labels, 1)\n",
    "    running_acc += get_accuracy(outputs, labels, 1)\n",
    "    \n",
    "    output_list.append(outputs.numpy())\n",
    "    target_list.append(target.numpy())\n",
    "    \n",
    "    string_predicted = \"\"\n",
    "    string_actual = \"\"\n",
    "    for i in range(len(pred)):\n",
    "        string_predicted += f\"{actors[pred[i]]}\"\n",
    "    for i in range(len(target_indices)):\n",
    "        string_actual += f\"{actors[target_indices[i]]}\"\n",
    "        \n",
    "    if 10< counter < 20:\n",
    "        # print(image)\n",
    "        image = inputs.squeeze(0)\n",
    "        image = image.detach().cpu().numpy()\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"PREDICTED: {string_predicted}\\nACTUAL: {string_actual}\")\n",
    "        plt.show()\n",
    "    \n",
    "test_error = running_error / counter\n",
    "print(f\"Test Error: \", test_error)\n",
    "\n",
    "out = np.array(output_list).squeeze(axis=1)\n",
    "tar = np.array(target_list).squeeze(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3a1d9cccb005>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_f1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F1 score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "f1 = get_f1_score(tar, out)\n",
    "precision = get_precision_score(tar, out)\n",
    "recall = get_recall_score(tar, out)\n",
    "print(\"F1 score: \", f1)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
